### 爬虫是什么？
爬虫即为Web Spider，将其视作一种在网页中抓取数据的工具即可。想象我们常用的搜索引擎，当你输入关键字搜索的时候，爬虫就在搜寻含有你关键字信息的网页，按照一定规则排序呈现在你眼前。

### URL与爬虫
爬虫抓取的是指定的网络资源、数据。读入并存储本地。按图索骥的图。用到的自然就是URL。

URL就是每天穿梭在万维网中的一个个链接。 

URL= 协议+端口（IP地址）+目录（路径）
协议:http \ https\ ftp 都是
 

#### urllib与urllib2 
urllib和urllib2出现在python2.x版本中，在3.x版本中，统一整合urllib 。
本系列教程采用 3.x版本
新建test_01.py文件。

---


    import urllib.request 
    url = "www.adastaybrave.com"        ##目标网页
    response= urllib.request.urlopen(url)
    html = response.read()
    print (html)
    

---
右键run之后你会在IDE(pycharm)的输出平台看到结果。
![1](http://7xq62e.com1.z0.glb.clouddn.com/web_spider(2)QQ%E6%88%AA%E5%9B%BE20160517161210.jpg)

IDE中没有换行，在shell下运行看到的更明显些。
![image](http://7xq62e.com1.z0.glb.clouddn.com/web_spider(2)shell.jpg)
可以看到一大串由b'开头的长字符串，你会看到熟悉的html标签，比如div。明显，這个我们右键审查网页元素时所看到的不一样，可读性太差。

故而我们需要解码操作unicode。

    html = html.decode('utf-8')  #结合网页的编码方式而定
    print (html)
    
再看就排版舒服且有可读性了

![image](http://7xq62e.com1.z0.glb.clouddn.com/web_spider(2)decode.jpg)

[這么几行代码还有源码！！！](https://github.com/ada-hs/Python-web_spider)


